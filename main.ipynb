{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from joblib import Parallel, delayed\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.losses import DiceLoss\n",
    "from monai.networks.nets import UNet, SwinUNETR, UNETR, SegResNet\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from monai.transforms import (\n",
    "    AddChanneld, Compose, LoadImaged, RandCropByPosNegLabeld,\n",
    "    Spacingd, ToTensord, NormalizeIntensityd, RandFlipd,\n",
    "    RandRotate90d, RandShiftIntensityd, RandAffined, RandSpatialCropd,\n",
    "    RandScaleIntensityd)\n",
    "    \n",
    "import numpy as np\n",
    "import random\n",
    "from glob import glob\n",
    "import re\n",
    "\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transformations and data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    \"\"\" Get transforms for training on FLAIR images and ground truth:\n",
    "    - Loads 3D images from Nifti file\n",
    "    - Adds channel dimention\n",
    "    - Normalises intensity\n",
    "    - Applies augmentations\n",
    "    - Crops out 32 patches of shape [96, 96, 96] that contain lesions\n",
    "    - Converts to torch.Tensor()\n",
    "    \"\"\"\n",
    "    return Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"label\"]),\n",
    "            AddChanneld(keys=[\"image\", \"label\"]),\n",
    "            NormalizeIntensityd(keys=[\"image\"], nonzero=True),\n",
    "            RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n",
    "            RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n",
    "            RandCropByPosNegLabeld(keys=[\"image\", \"label\"],\n",
    "                                   label_key=\"label\", image_key=\"image\",\n",
    "                                   spatial_size=(128, 128, 128), num_samples=32,\n",
    "                                   pos=4, neg=1),\n",
    "            RandSpatialCropd(keys=[\"image\", \"label\"],\n",
    "                             roi_size=(96, 96, 96),\n",
    "                             random_center=True, random_size=False),\n",
    "            RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=(0, 1, 2)),\n",
    "            RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=(0, 1)),\n",
    "            RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=(1, 2)),\n",
    "            RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=(0, 2)),\n",
    "            RandAffined(keys=['image', 'label'], mode=('bilinear', 'nearest'),\n",
    "                        prob=1.0, spatial_size=(96, 96, 96),\n",
    "                        rotate_range=(np.pi / 12, np.pi / 12, np.pi / 12),\n",
    "                        scale_range=(0.1, 0.1, 0.1), padding_mode='border'),\n",
    "            ToTensord(keys=[\"image\", \"label\"]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_val_transforms(keys=[\"image\", \"label\"], image_keys=[\"image\"]):\n",
    "    \"\"\" Get transforms for testing on FLAIR images and ground truth:\n",
    "    - Loads 3D images and masks from Nifti file\n",
    "    - Adds channel dimention\n",
    "    - Applies intensity normalisation to scans\n",
    "    - Converts to torch.Tensor()\n",
    "    \"\"\"\n",
    "    return Compose(\n",
    "        [\n",
    "            LoadImaged(keys=keys),\n",
    "            AddChanneld(keys=keys),\n",
    "            NormalizeIntensityd(keys=image_keys, nonzero=True),\n",
    "            ToTensord(keys=keys),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_train_dataloader(flair_path, gts_path, num_workers, batch_size, cache_rate=0.1):\n",
    "    \"\"\"\n",
    "    Get dataloader for training \n",
    "    Args:\n",
    "      flair_path: `str`, path to directory with FLAIR images from Train set.\n",
    "      gts_path:  `str`, path to directory with ground truth lesion segmentation \n",
    "                    binary masks images from Train set.\n",
    "      num_workers:  `int`,  number of worker threads to use for parallel processing\n",
    "                    of images\n",
    "      cache_rate:  `float` in (0.0, 1.0], percentage of cached data in total.\n",
    "    Returns:\n",
    "      monai.data.DataLoader() class object.\n",
    "    \"\"\"\n",
    "    flair = sorted(glob(os.path.join(flair_path, \"*FLAIR_isovox.nii.gz\")),\n",
    "                   key=lambda i: int(re.sub('\\D', '', i)))  # Collect all flair images sorted\n",
    "    segs = sorted(glob(os.path.join(gts_path, \"*gt_isovox.nii.gz\")),\n",
    "                  key=lambda i: int(re.sub('\\D', '', i)))  # Collect all corresponding ground truths\n",
    "\n",
    "    files = [{\"image\": fl, \"label\": seg} for fl, seg in zip(flair, segs)]\n",
    "\n",
    "    print(\"Number of training files:\", len(files))\n",
    "\n",
    "    ds = CacheDataset(data=files, transform=get_train_transforms(),\n",
    "                      cache_rate=cache_rate, num_workers=num_workers)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=True,\n",
    "                      num_workers=num_workers)\n",
    "\n",
    "\n",
    "def get_val_dataloader(flair_path, gts_path, num_workers, cache_rate=0.1, bm_path=None):\n",
    "    \"\"\"\n",
    "    Get dataloader for validation and testing. Either with or without brain masks.\n",
    "\n",
    "    Args:\n",
    "      flair_path: `str`, path to directory with FLAIR images.\n",
    "      gts_path:  `str`, path to directory with ground truth lesion segmentation \n",
    "                    binary masks images.\n",
    "      num_workers:  `int`,  number of worker threads to use for parallel processing\n",
    "                    of images\n",
    "      cache_rate:  `float` in (0.0, 1.0], percentage of cached data in total.\n",
    "      bm_path:   `None|str`. If `str`, then defines path to directory with\n",
    "                 brain masks. If `None`, dataloader does not return brain masks. \n",
    "    Returns:\n",
    "      monai.data.DataLoader() class object.\n",
    "    \"\"\"\n",
    "    flair = sorted(glob(os.path.join(flair_path, \"*FLAIR_isovox.nii.gz\")),\n",
    "                   key=lambda i: int(re.sub('\\D', '', i)))  # Collect all flair images sorted\n",
    "    segs = sorted(glob(os.path.join(gts_path, \"*_isovox.nii.gz\")),\n",
    "                  key=lambda i: int(re.sub('\\D', '', i)))  # Collect all corresponding ground truths\n",
    "\n",
    "    if bm_path is not None:\n",
    "        bms = sorted(glob(os.path.join(bm_path, \"*isovox_fg_mask.nii.gz\")),\n",
    "                     key=lambda i: int(re.sub('\\D', '', i)))  # Collect all corresponding brain masks\n",
    "\n",
    "        assert len(flair) == len(segs) == len(bms), f\"Some files must be missing: {[len(flair), len(segs), len(bms)]}\"\n",
    "\n",
    "        files = [\n",
    "            {\"image\": fl, \"label\": seg, \"brain_mask\": bm} for fl, seg, bm\n",
    "            in zip(flair, segs, bms)\n",
    "        ]\n",
    "\n",
    "        val_transforms = get_val_transforms(keys=[\"image\", \"label\", \"brain_mask\"])\n",
    "    else:\n",
    "        assert len(flair) == len(segs), f\"Some files must be missing: {[len(flair), len(segs)]}\"\n",
    "\n",
    "        files = [{\"image\": fl, \"label\": seg} for fl, seg in zip(flair, segs)]\n",
    "\n",
    "        val_transforms = get_val_transforms()\n",
    "\n",
    "    print(\"Number of validation files:\", len(files))\n",
    "\n",
    "    ds = CacheDataset(data=files, transform=val_transforms,\n",
    "                      cache_rate=cache_rate, num_workers=num_workers)\n",
    "    return DataLoader(ds, batch_size=1, shuffle=False,\n",
    "                      num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(mask1, mask2):\n",
    "    \"\"\"\n",
    "    Compute IoU for 2 binary masks.\n",
    "    \n",
    "    Args:\n",
    "      mask1: `numpy.ndarray`, binary mask.\n",
    "      mask2:  `numpy.ndarray`, binary mask of the same shape as `mask1`.\n",
    "    Returns:\n",
    "      Intersection over union between `mask1` and `mask2` (`float` in [0.0, 1.0]).\n",
    "    \"\"\"\n",
    "    return np.sum(mask1 * mask2) / np.sum(mask1 + mask2 - mask1 * mask2)\n",
    "    \n",
    "def lesion_f1_score(ground_truth, predictions, IoU_threshold=0.25, parallel_backend=None):\n",
    "    \"\"\"\n",
    "    Compute lesion-scale F1 score.\n",
    "    \n",
    "    Args:\n",
    "      ground_truth: `numpy.ndarray`, binary ground truth segmentation target,\n",
    "                     with shape [H, W, D].\n",
    "      predictions:  `numpy.ndarray`, binary segmentation predictions,\n",
    "                     with shape [H, W, D].\n",
    "      IoU_threshold: `float` in [0.0, 1.0], IoU threshold for max IoU between \n",
    "                     predicted and ground truth lesions to classify them as\n",
    "                     TP, FP or FN.\n",
    "      parallel_backend: `joblib.Parallel`, for parallel computation\n",
    "                     for different retention fractions.\n",
    "    Returns:\n",
    "      Intersection over union between `mask1` and `mask2` (`float` in [0.0, 1.0]).\n",
    "    \"\"\"\n",
    "\n",
    "    def get_tp_fp(label_pred, mask_multi_pred, mask_multi_gt):\n",
    "        mask_label_pred = (mask_multi_pred == label_pred).astype(int)\n",
    "        all_iou = [0.0]\n",
    "        # iterate only intersections\n",
    "        for int_label_gt in np.unique(mask_multi_gt * mask_label_pred):\n",
    "            if int_label_gt != 0.0:\n",
    "                mask_label_gt = (mask_multi_gt == int_label_gt).astype(int)\n",
    "                all_iou.append(intersection_over_union(\n",
    "                    mask_label_pred, mask_label_gt))\n",
    "        max_iou = max(all_iou)\n",
    "        if max_iou >= IoU_threshold:\n",
    "            return 'tp'\n",
    "        else:\n",
    "            return 'fp'\n",
    "\n",
    "    def get_fn(label_gt, mask_multi_pred, mask_multi_gt):\n",
    "        mask_label_gt = (mask_multi_gt == label_gt).astype(int)\n",
    "        all_iou = [0]\n",
    "        for int_label_pred in np.unique(mask_multi_pred * mask_label_gt):\n",
    "            if int_label_pred != 0.0:\n",
    "                mask_label_pred = (mask_multi_pred ==\n",
    "                                   int_label_pred).astype(int)\n",
    "                all_iou.append(intersection_over_union(\n",
    "                    mask_label_pred, mask_label_gt))\n",
    "        max_iou = max(all_iou)\n",
    "        if max_iou < IoU_threshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    mask_multi_pred_, n_les_pred = ndimage.label(predictions)\n",
    "    mask_multi_gt_, n_les_gt = ndimage.label(ground_truth)\n",
    "\n",
    "    if parallel_backend is None:\n",
    "        parallel_backend = Parallel(n_jobs=1)\n",
    "\n",
    "    process_fp_tp = partial(get_tp_fp, mask_multi_pred=mask_multi_pred_,\n",
    "                            mask_multi_gt=mask_multi_gt_)\n",
    "\n",
    "    tp_fp = parallel_backend(delayed(process_fp_tp)(label_pred)\n",
    "                             for label_pred in np.unique(mask_multi_pred_) if label_pred != 0)\n",
    "    counter = Counter(tp_fp)\n",
    "    tp = float(counter['tp'])\n",
    "    fp = float(counter['fp'])\n",
    "\n",
    "    process_fn = partial(get_fn, mask_multi_pred=mask_multi_pred_,\n",
    "                         mask_multi_gt=mask_multi_gt_)\n",
    "\n",
    "    fn = parallel_backend(delayed(process_fn)(label_gt)\n",
    "                          for label_gt in np.unique(mask_multi_gt_) if label_gt != 0)\n",
    "    fn = float(np.sum(fn))\n",
    "\n",
    "    f1 = 1.0 if tp + 0.5 * (fp + fn) == 0.0 else tp / (tp + 0.5 * (fp + fn))\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_norm_metric(ground_truth, predictions):\n",
    "    \"\"\"\n",
    "    Compute Normalised Dice Coefficient (nDSC), \n",
    "    False positive rate (FPR),\n",
    "    False negative rate (FNR) for a single example.\n",
    "    \n",
    "    Args:\n",
    "      ground_truth: `numpy.ndarray`, binary ground truth segmentation target,\n",
    "                     with shape [H, W, D].\n",
    "      predictions:  `numpy.ndarray`, binary segmentation predictions,\n",
    "                     with shape [H, W, D].\n",
    "    Returns:\n",
    "      Normalised dice coefficient (`float` in [0.0, 1.0]),\n",
    "      False positive rate (`float` in [0.0, 1.0]),\n",
    "      False negative rate (`float` in [0.0, 1.0]),\n",
    "      between `ground_truth` and `predictions`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Reference for normalized DSC\n",
    "    r = 0.001\n",
    "    # Cast to float32 type\n",
    "    gt = ground_truth.astype(\"float32\")\n",
    "    seg = predictions.astype(\"float32\")\n",
    "    im_sum = np.sum(seg) + np.sum(gt)\n",
    "    if im_sum == 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        if np.sum(gt) == 0:\n",
    "            k = 1.0\n",
    "        else:\n",
    "            k = (1 - r) * np.sum(gt) / (r * (len(gt.flatten()) - np.sum(gt)))\n",
    "        tp = np.sum(seg[gt == 1])\n",
    "        fp = np.sum(seg[gt == 0])\n",
    "        fn = np.sum(gt[seg == 0])\n",
    "        fp_scaled = k * fp\n",
    "        dsc_norm = 2. * tp / (fp_scaled + 2. * tp + fn)\n",
    "        return dsc_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndsc_aac_metric(ground_truth, predictions, uncertainties, parallel_backend=None):\n",
    "    \"\"\"\n",
    "    Compute area above Normalised Dice Coefficient (nDSC) retention curve for \n",
    "    one subject. `ground_truth`, `predictions`, `uncertainties` - are flattened \n",
    "    arrays of correponding 3D maps within the foreground mask only.\n",
    "    \n",
    "    Args:\n",
    "      ground_truth: `numpy.ndarray`, binary ground truth segmentation target,\n",
    "                     with shape [H * W * D]. \n",
    "      predictions:  `numpy.ndarray`, binary segmentation predictions,\n",
    "                     with shape [H * W * D].\n",
    "      uncertainties:  `numpy.ndarray`, voxel-wise uncertainties,\n",
    "                     with shape [H * W * D].\n",
    "      parallel_backend: `joblib.Parallel`, for parallel computation\n",
    "                     for different retention fractions.\n",
    "    Returns:\n",
    "      nDSC R-AAC (`float` in [0.0, 1.0]).\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_dice_norm(frac_, preds_, gts_, N_):\n",
    "        pos = int(N_ * frac_)\n",
    "        curr_preds = preds if pos == N_ else np.concatenate(\n",
    "            (preds_[:pos], gts_[pos:]))\n",
    "        return dice_norm_metric(gts_, curr_preds)\n",
    "\n",
    "    if parallel_backend is None:\n",
    "        parallel_backend = Parallel(n_jobs=1)\n",
    "\n",
    "    ordering = uncertainties.argsort()\n",
    "    gts = ground_truth[ordering].copy()\n",
    "    preds = predictions[ordering].copy()\n",
    "    N = len(gts)\n",
    "\n",
    "    # # Significant class imbalance means it is important to use logspacing between values\n",
    "    # # so that it is more granular for the higher retention fractions\n",
    "    fracs_retained = np.log(np.arange(200 + 1)[1:])\n",
    "    fracs_retained /= np.amax(fracs_retained)\n",
    "\n",
    "    process = partial(compute_dice_norm, preds_=preds, gts_=gts, N_=N)\n",
    "    dsc_norm_scores = np.asarray(\n",
    "        parallel_backend(delayed(process)(frac)\n",
    "                         for frac in fracs_retained)\n",
    "    )\n",
    "\n",
    "    return 1. - metrics.auc(fracs_retained, dsc_norm_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_connected_components(segmentation, l_min=9):\n",
    "    \"\"\"\n",
    "    Remove all lesions with less or equal amount of voxels than `l_min` from a \n",
    "    binary segmentation mask `segmentation`.\n",
    "    Args:\n",
    "      segmentation: `numpy.ndarray` of shape [H, W, D], with a binary lesions segmentation mask.\n",
    "      l_min:  `int`, minimal amount of voxels in a lesion.\n",
    "    Returns:\n",
    "      Binary lesion segmentation mask (`numpy.ndarray` of shape [H, W, D])\n",
    "      only with connected components that have more than `l_min` voxels.\n",
    "    \"\"\"\n",
    "    labeled_seg, num_labels = ndimage.label(segmentation)\n",
    "    label_list = np.unique(labeled_seg)\n",
    "    num_elements_by_lesion = ndimage.labeled_comprehension(segmentation, labeled_seg, label_list, np.sum, float, 0)\n",
    "\n",
    "    seg2 = np.zeros_like(segmentation)\n",
    "    for i_el, n_el in enumerate(num_elements_by_lesion):\n",
    "        if n_el > l_min:\n",
    "            current_voxels = np.stack(np.where(labeled_seg == i_el), axis=1)\n",
    "            seg2[current_voxels[:, 0],\n",
    "                 current_voxels[:, 1],\n",
    "                 current_voxels[:, 2]] = 1\n",
    "    return seg2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renyi_entropy_of_expected(probs, alpha=0.8):\n",
    "    \"\"\"\n",
    "    Renyi entropy is a generalised version of Shannon - the two are equivalent for alpha=1\n",
    "    :param probs: array [num_models, num_voxels_X, num_voxels_Y, num_voxels_Z, num_classes]\n",
    "    :return: array [num_voxels_X, num_voxels_Y, num_voxels_Z,]\n",
    "    \"\"\"\n",
    "    scale = 1. / (1. - alpha)\n",
    "    mean_probs = np.mean(probs, axis=0)\n",
    "    return scale * np.log( np.sum(mean_probs**alpha, axis=-1) )\n",
    "\n",
    "def renyi_expected_entropy(probs, alpha=0.8):\n",
    "    \"\"\"\n",
    "    :param probs: array [num_models, num_voxels_X, num_voxels_Y, num_voxels_Z, num_classes]\n",
    "    :return: array [num_voxels_X, num_voxels_Y, num_voxels_Z,]\n",
    "    \"\"\"\n",
    "    scale = 1. / (1. - alpha)\n",
    "    return np.mean( scale * np.log( np.sum(probs**alpha, axis=-1) ), axis=0)\n",
    "\n",
    "\n",
    "def entropy_of_expected(probs, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    :param probs: array [num_models, num_voxels_X, num_voxels_Y, num_voxels_Z, num_classes]\n",
    "    :return: array [num_voxels_X, num_voxels_Y, num_voxels_Z,]\n",
    "    \"\"\"\n",
    "    mean_probs = np.mean(probs, axis=0)\n",
    "    log_probs = -np.log(mean_probs + epsilon)\n",
    "    return np.sum(mean_probs * log_probs, axis=-1)\n",
    "\n",
    "def expected_entropy(probs, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    :param probs: array [num_models, num_voxels_X, num_voxels_Y, num_voxels_Z, num_classes]\n",
    "    :return: array [num_voxels_X, num_voxels_Y, num_voxels_Z,]\n",
    "    \"\"\"\n",
    "    log_probs = -np.log(probs + epsilon)\n",
    "    return np.mean(np.sum(probs * log_probs, axis=-1), axis=0)\n",
    "\n",
    "\n",
    "def ensemble_uncertainties_classification(probs, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    :param probs: array [num_models, num_voxels_X, num_voxels_Y, num_voxels_Z, num_classes]\n",
    "    :return: Dictionary of uncertainties\n",
    "    \"\"\"\n",
    "    mean_probs = np.mean(probs, axis=0)\n",
    "    mean_lprobs = np.mean(np.log(probs + epsilon), axis=0)\n",
    "    conf = np.max(mean_probs, axis=-1)\n",
    "\n",
    "    eoe = entropy_of_expected(probs, epsilon)\n",
    "    exe = expected_entropy(probs, epsilon)\n",
    "\n",
    "    mutual_info = eoe - exe\n",
    "\n",
    "    epkl = -np.sum(mean_probs * mean_lprobs, axis=-1) - exe\n",
    "\n",
    "    uncertainty = {'confidence': -1 * conf,\n",
    "                   'entropy_of_expected': eoe,\n",
    "                   'expected_entropy': exe,\n",
    "                   'mutual_information': mutual_info,\n",
    "                   'epkl': epkl,\n",
    "                   'reverse_mutual_information': epkl - mutual_info,\n",
    "                   }\n",
    "\n",
    "    return uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,optimizer, loss_function, gamma_focal, dice_weight, focal_weight, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        n_samples = batch_data[\"image\"].size(0)\n",
    "        for m in range(0,batch_data[\"image\"].size(0), 8):\n",
    "            step += 8\n",
    "            inputs, labels = (\n",
    "                batch_data[\"image\"][m:(m+8)].to(device),\n",
    "                batch_data[\"label\"][m:(m+8)].type(torch.LongTensor).to(device))\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Dice loss\n",
    "            loss1 = loss_function(outputs, labels)\n",
    "            # Focal loss\n",
    "            ce_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "            ce = ce_loss(outputs, torch.squeeze(labels, dim=1))\n",
    "            pt = torch.exp(-ce)\n",
    "            loss2 = (1 - pt)**gamma_focal * ce \n",
    "            loss2 = torch.mean(loss2)\n",
    "            loss = dice_weight * loss1 + focal_weight * loss2              \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            if step % 100 == 0:\n",
    "                step_print = int(step/2)\n",
    "                print(f\"{step_print}/{(len(train_loader)*n_samples) // (train_loader.batch_size*2)}, train_loss: {loss.item():.4f}\")\n",
    "    epoch_loss /= step_print\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validaion function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model,val_loader, dice_norm_metric, roi_size, sw_batch_size, act, thresh,device):\n",
    "    model.val()\n",
    "    metric_sum = 0.0\n",
    "    metric_count = 0\n",
    "    for val_data in val_loader:\n",
    "        val_inputs, val_labels = (\n",
    "            val_data[\"image\"].to(device),\n",
    "            val_data[\"label\"].to(device)\n",
    "            )\n",
    "        \n",
    "        val_outputs = sliding_window_inference(val_inputs, roi_size, \n",
    "                                                sw_batch_size, \n",
    "                                                model, mode='gaussian')\n",
    "        \n",
    "        gt = np.squeeze(val_labels.cpu().numpy())\n",
    "        \n",
    "        seg = act(val_outputs).cpu().numpy()\n",
    "        seg= np.squeeze(seg[0,1])\n",
    "        seg[seg >= thresh] = 1\n",
    "        seg[seg < thresh] = 0\n",
    "        \n",
    "        value = dice_norm_metric(ground_truth=gt.flatten(), predictions=seg.flatten())\n",
    "\n",
    "        metric_count += 1\n",
    "        metric_sum += value.sum().item()\n",
    "    \n",
    "    return metric_sum / metric_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self) -> None:\n",
    "        self.lr = 1e-5\n",
    "        self.n_epochs = 300\n",
    "        self.seed = 1\n",
    "        self.path_train_flair = r\"C:\\Users\\Talal\\Desktop\\ML703\\project\\train\\flair\"\n",
    "        self.path_train_gts = r\"C:\\Users\\Talal\\Desktop\\ML703\\project\\train\\gt\"\n",
    "        self.path_train_bm = r\"C:\\Users\\Talal\\Desktop\\ML703\\project\\train\\fg_mask\"\n",
    "\n",
    "        self.path_val_flair = r\"C:\\Users\\Talal\\Desktop\\ML703\\project\\dev_in\\flair\"\n",
    "        self.path_val_gts   =  r\"C:\\Users\\Talal\\Desktop\\ML703\\project\\dev_in\\gt\"\n",
    "        self.path_val_bm   =  r\"C:\\Users\\Talal\\Desktop\\ML703\\project\\dev_in\\fg_mask\"\n",
    "\n",
    "        self.path_test_flair = r\"C:\\Users\\Talal\\Desktop\\ML703\\project\\shifts_ms_pt2\\shifts_ms_pt2\\best\\eval_in\\flair\"\n",
    "        self.path_test_gts   =  r\"C:\\Users\\Talal\\Desktop\\ML703\\project\\shifts_ms_pt2\\shifts_ms_pt2\\best\\eval_in\\gt\"\n",
    "        self.path_test_bm   =  r\"C:\\Users\\Talal\\Desktop\\ML703\\project\\shifts_ms_pt2\\shifts_ms_pt2\\best\\eval_in\\fg_mask\"\n",
    "\n",
    "        self.path_model = r\"C:\\Users\\Talal\\Desktop\\ML703\\project\"\n",
    "        self.num_models = 1\n",
    "\n",
    "        self.num_workers = 4\n",
    "        self.n_jobs = 2\n",
    "        self.path_save = \"\"   \n",
    "        self.val_interval = 5\n",
    "        self.threshold = 0.4\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()\n",
    "seed_val = args.seed\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "path_save = args.path_save\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training files: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 3/3 [00:00<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation files: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_train_dataloader(flair_path=args.path_train_flair, \n",
    "                                        gts_path=args.path_train_gts, \n",
    "                                        num_workers=args.num_workers, \n",
    "                                        batch_size=1)\n",
    "val_loader = get_val_dataloader(flair_path=args.path_test_flair, \n",
    "                                    gts_path=args.path_test_gts, \n",
    "                                    num_workers=args.num_workers,\n",
    "                                    bm_path=args.path_test_bm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=2,\n",
    "        channels=(32, 64, 128, 256, 512),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SegResNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNETR(in_channels=1,\n",
    "             out_channels=4,\n",
    "             img_size=(96,96,96),\n",
    "             feature_size=32,\n",
    "             norm_name='batch').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SwinUNETR(img_size=(96,96,96),\n",
    "                        in_channels=1,\n",
    "                        out_channels=4,\n",
    "                        feature_size=48).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting the loss function & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = DiceLoss(to_onehot_y=True, \n",
    "                             softmax=True, sigmoid=False,\n",
    "                             include_background=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), args.lr)\n",
    "act = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poch_num = args.n_epochs\n",
    "val_interval = args.val_interval\n",
    "thresh = args.threshold\n",
    "gamma_focal = 2.0\n",
    "dice_weight = 0.5\n",
    "focal_weight = 1.0\n",
    "roi_size = (96, 96, 96)\n",
    "sw_batch_size = 4\n",
    "epoch_num = args.n_epochs\n",
    "\n",
    "best_metric, best_metric_epoch = -1, -1\n",
    "epoch_loss_values, metric_values = [], []\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
    "    epoch_loss = train(model,train_loader,optimizer, loss_function, gamma_focal, dice_weight, focal_weight, device)\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    ''' Validation '''\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        metric = validation(model, dice_norm_metric, val_loader, device, roi_size, sw_batch_size, act, thresh, device)\n",
    "        metric_values.append(metric)\n",
    "        if metric > best_metric:\n",
    "            best_metric = metric\n",
    "            best_metric_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), os.path.join(path_save, \"Best_model_finetuning.pth\"))\n",
    "            print(\"saved new best metric model\")\n",
    "        \n",
    "        print(f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                            f\"\\nbest mean dice: {best_metric:.4f} at epoch: {best_metric_epoch}\"\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/9\n",
      "nDSC:\t62.0949 +- 3.9508\n",
      "Lesion F1 score:\t20.7869 +- 5.8680\n",
      "nDSC R-AUC:\t31.6925 +- 6.2028\n"
     ]
    }
   ],
   "source": [
    "''' Load trained models  '''\n",
    "K = args.num_models\n",
    "models = []\n",
    "for i in range(K):\n",
    "    models.append(UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=2,\n",
    "        channels=(32, 64, 128, 256, 512),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=0).to(device)\n",
    "                    )\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    model.load_state_dict(torch.load(os.path.join(args.path_model,\n",
    "                                                    f\"seed{i + 1}\",\n",
    "                                                    \"Best_model_finetuning.pth\")))\n",
    "    model.eval()\n",
    "\n",
    "act = torch.nn.Softmax(dim=1)\n",
    "th = args.threshold\n",
    "roi_size = (96, 96, 96)\n",
    "sw_batch_size = 4\n",
    "\n",
    "ndsc, f1, ndsc_aac = [], [], []\n",
    "\n",
    "''' Evaluatioin loop '''\n",
    "with Parallel(n_jobs=args.n_jobs) as parallel_backend:\n",
    "    with torch.no_grad():\n",
    "        for count, batch_data in enumerate(val_loader):\n",
    "            inputs, gt, brain_mask = (\n",
    "                batch_data[\"image\"].to(device),\n",
    "                batch_data[\"label\"].cpu().numpy(),\n",
    "                batch_data[\"brain_mask\"].cpu().numpy()\n",
    "            )\n",
    "\n",
    "            # get ensemble predictions\n",
    "            all_outputs = []\n",
    "            for model in models:\n",
    "                outputs = sliding_window_inference(inputs, roi_size,\n",
    "                                                    sw_batch_size, model,\n",
    "                                                    mode='gaussian')\n",
    "                outputs = act(outputs).cpu().numpy()\n",
    "                outputs = np.squeeze(outputs[0, 1])\n",
    "                all_outputs.append(outputs)\n",
    "            all_outputs = np.asarray(all_outputs)\n",
    "\n",
    "            # obtain binary segmentation mask\n",
    "            seg = np.mean(all_outputs, axis=0)\n",
    "            seg[seg >= th] = 1\n",
    "            seg[seg < th] = 0\n",
    "            seg = np.squeeze(seg)\n",
    "            seg = remove_connected_components(seg)\n",
    "\n",
    "            gt = np.squeeze(gt)\n",
    "            brain_mask = np.squeeze(brain_mask)\n",
    "\n",
    "            # compute reverse mutual information uncertainty map\n",
    "            uncs_map = ensemble_uncertainties_classification(np.concatenate(\n",
    "                (np.expand_dims(all_outputs, axis=-1),\n",
    "                    np.expand_dims(1. - all_outputs, axis=-1)),\n",
    "                axis=-1))['reverse_mutual_information']\n",
    "\n",
    "            # compute metrics\n",
    "            ndsc += [dice_norm_metric(ground_truth=gt, predictions=seg)]\n",
    "            f1 += [lesion_f1_score(ground_truth=gt,\n",
    "                                    predictions=seg,\n",
    "                                    IoU_threshold=0.5,\n",
    "                                    parallel_backend=parallel_backend)]\n",
    "            ndsc_aac += [ndsc_aac_metric(ground_truth=gt[brain_mask == 1].flatten(),\n",
    "                                            predictions=seg[brain_mask == 1].flatten(),\n",
    "                                            uncertainties=uncs_map[brain_mask == 1].flatten(),\n",
    "                                            parallel_backend=parallel_backend)]\n",
    "\n",
    "            # for nervous people\n",
    "            if count % 10 == 0:\n",
    "                print(f\"Processed {count}/{len(val_loader)}\")\n",
    "\n",
    "ndsc = np.asarray(ndsc) * 100.\n",
    "f1 = np.asarray(f1) * 100.\n",
    "ndsc_aac = np.asarray(ndsc_aac) * 100.\n",
    "\n",
    "print(f\"nDSC:\\t{np.mean(ndsc):.4f} +- {np.std(ndsc):.4f}\")\n",
    "print(f\"Lesion F1 score:\\t{np.mean(f1):.4f} +- {np.std(f1):.4f}\")\n",
    "print(f\"nDSC R-AUC:\\t{np.mean(ndsc_aac):.4f} +- {np.std(ndsc_aac):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcfa5253a3c26d840d5a552562af87844e79aa37d650ff1d8a245d8823a54adf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
